= Bedrock Anthropic Chat

https://www.anthropic.com/product[Anthropic's Claude] is an AI assistant based on Anthropicâ€™s research into training helpful, honest, and harmless AI systems.

The Claude model has the following high level features

* 200k Token Context Window: Claude boasts a generous token capacity of 200,000, making it ideal for handling extensive information in applications like technical documentation, codebases, and literary works.
* Supported Tasks: Claude's versatility spans tasks such as summarization, Q&A, trend forecasting, and document comparisons, enabling a wide range of applications from dialogues to content generation.
* AI Safety Features: Built on Anthropic's safety research, Claude prioritizes helpfulness, honesty, and harmlessness in its interactions, reducing brand risk and ensuring responsible AI behavior.

The https://aws.amazon.com/bedrock/claude[AWS Bedrock Anthropic Model Page] and https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html[Amazon Bedrock User Guide] contains detailed information on how to use the AWS hosted model.

== Getting Started

Refer to the xref:api/clients/bedrock.adoc[Spring AI documentation on Amazon Bedrock] for setting up API access.

The link:./src/main/java/org/springframework/ai/bedrock/anthropic/BedrockAnthropicChatClient.java[BedrockAnthropicChatClient] implements the `ChatClient` and `StreamingChatClient` and uses the `AnthropicChatBedrockApi` library to connect to the Bedrock Anthropic service.

Add the `spring-ai-bedrock` dependency to your project's Maven `pom.xml` file:

[source,xml]
----
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-bedrock</artifactId>
    <version>0.8.0-SNAPSHOT</version>
</dependency>
----

or to your Gradle `build.gradle` build file.

[source,gradle]
----
dependencies {
    implementation 'org.springframework.ai:spring-ai-bedrock:0.8.0-SNAPSHOT'
}
----

NOTE: Refer to the xref:getting-started.adoc#_dependency_management[Dependency Management] section to add Milestone and/or Snapshot Repositories to your build file.

Next, create an `BedrockAnthropicChatClient` instance and use it to text generations requests:

[source,java]
----
AnthropicChatBedrockApi anthropicApi =  new AnthropicChatBedrockApi(
    AnthropicChatBedrockApi.AnthropicModel.CLAUDE_V2.id(),
    EnvironmentVariableCredentialsProvider.create(),
    Region.EU_CENTRAL_1.id(),
    new ObjectMapper());

BedrockAnthropicChatClient chatClient = new BedrockAnthropicChatClient(anthropicApi,
    AnthropicChatOptions.builder()
        .withTemperature(0.6f)
        .withTopK(10)
        .withTopP(0.8f)
        .withMaxTokensToSample(100)
        .withAnthropicVersion(AnthropicChatBedrockApi.DEFAULT_ANTHROPIC_VERSION)
        .build());

ChatResponse response = chatClient.call(
    new Prompt("Generate the names of 5 famous pirates."));

// Or with streaming responses
Flux<ChatResponse> response = chatClient.stream(
    new Prompt("Generate the names of 5 famous pirates."));
----

=== AnthropicChatClient Auto-configuration

or you can leverage the `spring-ai-bedrock-ai-spring-boot-starter` Spring Boot starter:

[source,xml]
----
<dependency>
  <groupId>org.springframework.ai</groupId>
  <artifactId>spring-ai-bedrock-ai-spring-boot-starter</artifactId>
  <version>0.8.0-SNAPSHOT</version>
</dependency>
----

==== Enable Anthropic Support

Spring AI defines a configuration property named `spring.ai.bedrock.anthropic.chat.enabled` that you should set to `true` to enable support for Anthropic.

Exporting environment variables in one way to set this configuration property.

[source,shell]
----
export SPRING_AI_BEDROCK_ANTHROPIC_CHAT_ENABLED=true
----

==== Sample Code

This will create a `ChatClient` implementation that you can inject into your class.

Create an `application.properties` file in the `src/main/resources` directory and add the following properties to configure the Anthropic Chat client.

[source]
----
spring.ai.bedrock.anthropic.chat.enabled=true
spring.ai.bedrock.anthropic.chat.options.temperature=0.8
----

Here is an example of a simple `@Controller` class that uses the `ChatClient` implementation.

[source,java]
----
@RestController
public class ChatController {

    private final ChatClient chatClient;

    @Autowired
    public ChatController(ChatClient chatClient) {
        this.chatClient = chatClient;
    }

    @GetMapping("/ai/generate")
    public Map generate(@RequestParam(value = "message", defaultValue = "Tell me a joke") String message) {
        return Map.of("generation", chatClient.generate(message));
    }
}
----

==== Bedrock Properties

The prefix `spring.ai.bedrock.aws` is the property prefix to configure the connection to AWS Bedrock.

[cols="3,3,1"]
|====
| Property | Description | Default

| spring.ai.bedrock.aws.region     |   AWS region to use. | us-east-1
| spring.ai.bedrock.aws.access-key | AWS access key.  | -
| spring.ai.bedrock.aws.secret-key | AWS secret key.  | -
|====

The prefix `spring.ai.bedrock.anthropic.chat` is the property prefix that configures the `ChatClient` implementation for Claude.

[cols="2,5,1"]
|====
| Property | Description | Default

| spring.ai.bedrock.anthropic.chat.enable | Enable Bedrock Anthropic chat client. Disabled by default | false
| spring.ai.bedrock.anthropic.chat.model  | The model id to use. See the `AnthropicChatModel` for the supported models.  | anthropic.claude-v2
| spring.ai.bedrock.anthropic.chat.options.temperature  | Controls the randomness of the output. Values can range over [0.0,1.0]  | 0.8
| spring.ai.bedrock.anthropic.chat.options.topP  | The maximum cumulative probability of tokens to consider when sampling.  | AWS Bedrock default
| spring.ai.bedrock.anthropic.chat.options.topK  | Specify the number of token choices the generative uses to generate the next token.  | AWS Bedrock default
| spring.ai.bedrock.anthropic.chat.options.stopSequences  | Configure up to four sequences that the generative recognizes. After a stop sequence, the generative stops generating further tokens. The returned text doesn't contain the stop sequence.  | 10
| spring.ai.bedrock.anthropic.chat.options.anthropicVersion  | The version of the generative to use. | bedrock-2023-05-31
| spring.ai.bedrock.anthropic.chat.options.maxTokensToSample  | Specify the maximum number of tokens to use in the generated response. Note that the models may stop before reaching this maximum. This parameter only specifies the absolute maximum number of tokens to generate. We recommend a limit of 4,000 tokens for optimal performance. | 500
|====

Look at the Spring AI enumeration `AnthropicChatModel` for other model IDs.  The other value supported is `anthropic.claude-instant-v1`.

Model ID values can also be found in the https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids-arns.html[AWS Bedrock documentation for base model IDs].

== Appendices

=== Using low-level AnthropicChatBedrockApi Library

The link:./src/main/java/org/springframework/ai/bedrock/anthropic/api/AnthropicChatBedrockApi.java[AnthropicChatBedrockApi] provides is lightweight Java client on top of AWS Bedrock link:https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-claude.html[Anthropic Claude models].

Following class diagram illustrates the AnthropicChatBedrockApi interface and building blocks:

image::bedrock/bedrock-anthropic-chat-api.png[AnthropicChatBedrockApi Class Diagram]

The AnthropicChatBedrockApi supports the `anthropic.claude-instant-v1` and `anthropic.claude-v2` models.

Also the AnthropicChatBedrockApi supports both synchronous (e.g. `chatCompletion()`) and streaming (e.g. `chatCompletionStream()`) responses.

Here is a simple snippet how to use the api programmatically:

[source,java]
----
AnthropicChatBedrockApi anthropicChatApi = new AnthropicChatBedrockApi(
   AnthropicModel.CLAUDE_V2.id(),
   Region.EU_CENTRAL_1.id());

AnthropicChatRequest request = AnthropicChatRequest
  .builder(String.format(AnthropicChatBedrockApi.PROMPT_TEMPLATE, "Name 3 famous pirates"))
  .withTemperature(0.8f)
  .withMaxTokensToSample(300)
  .withTopK(10)
  // .withStopSequences(List.of("\n\nHuman:"))
  .build();

AnthropicChatResponse response = anthropicChatApi.chatCompletion(request);

System.out.println(response.completion());

// Streaming response
Flux<AnthropicChatResponse> responseStream = anthropicChatApi.chatCompletionStream(request);

List<AnthropicChatResponse> responses = responseStream.collectList().block();

System.out.println(responses);
----

Follow the link:./src/main/java/org/springframework/ai/bedrock/anthropic/api/AnthropicChatBedrockApi.java[AnthropicChatBedrockApi.java]'s JavaDoc for further information.
