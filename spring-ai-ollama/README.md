## Ollama

Ollama lets you ge tup an running with large language models locally

Refer to the official [README](https://github.com/jmorganca/ollama) to get started.

Note, installing `ollama run llama2` will download a 4GB docker image.

You can run the disabled test in `OllamaClientTests.java` to kick the tires.